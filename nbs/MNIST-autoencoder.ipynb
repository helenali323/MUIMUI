{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's an autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder is a machine learning system that takes an input and attempts to produce output that matches the input as closely as possible.  This useless and simple task doesn't seem to warrant the attention of machine learning (for example, a function that returns its input is a perfect \"autoencoder\"), but the point of an autoencoder is the journey, not the destination.  Typically, restrictions are placed on the autoencoder so that in the course of training, some other objective is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ae flowchart](https://alanbertl.com/wp-content/uploads/2018/12/AE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An autoencoder consists of two components, an encoder and a decoder.  Between them sits the code layer, which isn't so much a component unto itself as the format of the output of the encoder after processing its input.  \n",
    "\n",
    "As an example of a useful task for an autoencoder, suppose we make the code layer small in memory compared to the input size.  We then train the autoencoder over a dataset to encode the inputs into this small memory space, and then reconstruct them as best it can with the decoder.  If the autoencoder is successful and is able to generalize beyond the dataset, voila, we've created a compression algorithm for that class of data.\n",
    "\n",
    "Other objectives might be feature extraction at the code layer, repurposing the pretrained the encoder/decoder for some other task, denoising, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Autoencoder using fast.ai 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few months ago I created an autoencoder for the MNIST dataset using the old version of the free [fast.ai](https://www.fast.ai/) Python machine learning library used in their online [deep learning class](https://course.fast.ai/).  I did it for several reasons: I'd recently learned about autoencoders and wanted to implement one, I wanted to use something like an autoencoder for a project I was working on, and I wanted to get a better feel for [PyTorch](https://pytorch.org/) and the fast.ai library.\n",
    "\n",
    "I've been wanting to do a blog post with a simple autoencoder implementation, and instead of just pruning the notebook I already had, I've decided to update it to the latest version of fast.ai.  This is for my benefit since working through the online class I've exclusively been using the old version.\n",
    "\n",
    "This post gives the full Python code for implementing the autoencoder using the fast.ai library (and is downloadable as a [Jupyter notebook](https://jupyter.org/)).  A familiarity with Python is helpful to read the code, and although I try to briefly describe what's happening throughout, a familiarity with deep learning is assumed.  I'll also periodically refer to features in the old version of fast.ai's library to describe what I learned about the new version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fast.ai library sits on top of PyTorch, an open-source machine learning library for Python.\n",
    "\n",
    "Version 1.0 splits the highest levels of the library into four implementation packages, `fastai.vision` (for image applications), `fastai.text` (for language procession), `fastai.tabular` (for tabular/structured data), and `fastai.collab` (for collaborative filtering).  I worked with MNIST data so `fastai.vision` is what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.vision import *\n",
    "from fastai.data_block import *\n",
    "from fastai.basic_train import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a GPU.  I haven't made allowances in this code for cases where a GPU isn't available, so if you'd like to try this code for CPU only, be aware some tinkering will be required later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data shaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-05 05:18:06--  https://pjreddie.com/media/files/mnist_train.csv\n",
      "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
      "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 109575994 (104M) [application/octet-stream]\n",
      "Saving to: ‘mnist_train.csv’\n",
      "\n",
      "mnist_train.csv     100%[===================>] 104.50M  1.60MB/s    in 40s     \n",
      "\n",
      "2019-05-05 05:18:46 (2.63 MB/s) - ‘mnist_train.csv’ saved [109575994/109575994]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pjreddie.com/media/files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-05 05:18:56--  https://pjreddie.com/media/files/mnist_test.csv\n",
      "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
      "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18289443 (17M) [application/octet-stream]\n",
      "Saving to: ‘mnist_test.csv’\n",
      "\n",
      "mnist_test.csv      100%[===================>]  17.44M  4.44MB/s    in 4.2s    \n",
      "\n",
      "2019-05-05 05:19:00 (4.16 MB/s) - ‘mnist_test.csv’ saved [18289443/18289443]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://pjreddie.com/media/files/mnist_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv mnist_train.csv data/train.csv\n",
    "!mv mnist_test.csv data/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data set includes a set of $28\\times 28$ images of handwritten digits with their labels, 0-9.  I got my copy of the [dataset](https://www.kaggle.com/c/digit-recognizer/data) in a weird format from [kaggle](https://www.kaggle.com/), consisting of a CSV with the label and a column *for each pixel in the image* containing an int from 0-255.\n",
    "\n",
    "As a result, I had to do a bit of processing to present the data to fast.ai in a format it understands.  Revisiting this, I could use a version of the dataset that uses the actual images, but this type of preprocessing gives me a chance to learn how the newer fast.ai version handles data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/\"\n",
    "test_csv = f'{PATH}test.csv'\n",
    "train_csv = f'{PATH}train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use pandas to read the CSVs.  In this application the data from `test_df` will go unused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv, header=None)\n",
    "test_df = pd.read_csv(test_csv, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at the data firsthand.  The column on the left gives the image number, and the columns continue all the way out to `pixel783`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0    5    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    4    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    1    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    9    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the pixels are 0 (black), but let's find some that aren't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>346</th>\n",
       "      <th>347</th>\n",
       "      <th>348</th>\n",
       "      <th>349</th>\n",
       "      <th>350</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>353</th>\n",
       "      <th>354</th>\n",
       "      <th>355</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>190</td>\n",
       "      <td>253</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>240</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>205</td>\n",
       "      <td>253</td>\n",
       "      <td>251</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>247</td>\n",
       "      <td>176</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>78</td>\n",
       "      <td>245</td>\n",
       "      <td>253</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   346  347  348  349  350  351  352  353  354  355\n",
       "0    0    0   11  190  253   70    0    0    0    0\n",
       "1  252  240   71   19   28    0    0    0    0    0\n",
       "2    0    0    0    0    0    0    0    0    0  163\n",
       "3    0    0    0    0   32  205  253  251  126    0\n",
       "4  247  176    9    0    0    8   78  245  253  129"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:5,346:356]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset was created with the intent of training a classifier, something that could identify the digit from the image.  We're not going to do that, so I'll throw away the labels.  Then, I'll convert the 0-255 pixel data to a float in $[0,1]$ and reshape the $784$-long vectors into $28\\times 28$ arrays.\n",
    "\n",
    "Since fast.ai mostly expects image data in 3 color channels, we'll duplicate the array for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "x = train_df.drop(labels=0, axis=1).values\n",
    "x = x/255.\n",
    "print(x.shape)\n",
    "x = x.reshape(-1, 28, 28)\n",
    "x = np.stack([x,x,x],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we have the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape describes the type of tensor our input data occupies.  A tensor is a matrix but with any number of dimensions.  Our data is a 4-d tensor with dimensions $42000\\times 3\\times 28\\times 28$.  The first dimension is the size of our dataset, the second dimension is the three color channels, and the remaining dimensions represent the width and height of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the images actually look like (using fast.ai's `Image` class after casting the numpy arrays to a PyTorch tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Image(Tensor(np.concatenate(x[10:20],2))).show(figsize=(10,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in my old notebook, I set `y=x` and split them both into training and validation sets, but as we'll see, that's been automated in this version of fast.ai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting data for fast.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up till now we've just used pandas and numpy, but now I have to get into the nitty gritty of fast.ai's new `data_block` API.  The version used in the online course used `Dataset` objects which could be used to create `DataLoader` objects, which could then get wrapped into `ModelData` objects and used with a model to build a `Learner`.\n",
    "\n",
    "`Dataset` and `DataLoader` objects are still in the underlying PyTorch framework, but they have been abstracted in the new version using `ItemLists`, which is like a more intuitive and flexible `Dataset`, and `Databunch`, which acts much like the old `ModelData` object, but works for more applications.  \n",
    "\n",
    "I actually found myself writing something with some of the functionality of an `ItemList` in one of my projects so I'm not surprised to something like it eventually became part of the library.  For our purposes an `ItemList` is a `numpy.ndarray` of objects, with all the nice slicing functionality that entails, and methods that prepare the data your model will need to use.  The point is that directly storing your data in the array is often memory prohibitive, so instead for example you might store the filenames of images in your `ItemList` object `mydata` and then retrieve the tensor of pixel data only when `mydata.get` is called.  In fact this is the default behavior of the subclass `ImageItemList` used by the `fastai.vision` module.\n",
    "\n",
    "Since I don't have the MNIST image files on disk, and the MNIST image data is relatively small, I've decided to store it directly.  It turns out that the `fastai.data_block` API is probably more suited to me just loading data out of the `train_df` `DataFrame` instance and reshaping it as needed, but trying to do it this way taught me quite a bit about how the API works.\n",
    "\n",
    "First I want a custom class that has some of the functionality of `ImageItemList`, but pulls data directly from its `.items` property like `ItemList`, and is treated as regression data like a `FloatList`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "totensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(fname):\n",
    "    im = cv2.imread(str(fname))\n",
    "    # openCV by default uses BGR ordering but we need RBG usually\n",
    "    # height x width x channels\n",
    "    return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArraysImageItemList(ImageItemList,FloatList):\n",
    "    def __init__(self, items:Iterator, log:bool=False, **kwargs):\n",
    "        if isinstance(items, ItemList):\n",
    "            items = items.items\n",
    "        super(FloatList,self).__init__(items,**kwargs)\n",
    "    \n",
    "    def get(self,i):\n",
    "        return Tensor(super(FloatList,self).get(i).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_il = VAEImageItemList(ItemList(img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 512])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_il[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_il)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import ItemList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = list(p.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArraysImageItemList(ImageImageList,FloatList):\n",
    "    def __init__(self, items:Iterator, log:bool=False, **kwargs):\n",
    "        if isinstance(items, ItemList):\n",
    "            items = items.items\n",
    "        super(FloatList,self).__init__(items,**kwargs)\n",
    "    \n",
    "    def get(self,i):\n",
    "        return Tensor(super(FloatList,self).get(i).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to split our data into training and validation (and optionally test) sets.  This is automated in the new version in a very nice way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ils = x_il.random_split_by_pct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add labels to form a `LabelLists`.  Since our desired output is the same as our inputs, we will pass the training and validation sets in our `ItemLists` class as our training and validation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = x_ils.label_from_lists(x_ils.train, x_ils.valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap up the data preparation we create a databunch.  Again the library can handle this automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lls.databunch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be honest, my instinct was to pair the raw data with labels (desired output) in a `LabelList` before splitting into training and validation sets.  The API appeared to support it, but I got a lot of unexpected behavior.  I later learned the preferred method is to split *then* pair with labels as you see above.  This seems less natural to me, as you have to take steps to ensure the training and validation inputs stay matched with training and validation outputs, but it may just take some getting used to on my part.  It certainly didn't turn out to be an issue in this application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder using ResNET34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ResNET](https://arxiv.org/abs/1512.03385) is a deep learning architecture developed for image classification, specifically performance on the [ImageNet](http://www.image-net.org/) dataset.  This might be overkill, but I created the encoder with a ResNET34 spine (all layers except those specific to classification) pretrained on ImageNet.  These resources are available, free, and easy to access using fast.ai, so why not use them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = vision.models.resnet34(pretrained = True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind using pretrained ResNET is that it's a network that already \"knows\" how to recognize images, and part of that skill is recognizing the important features that distinguish the types of images that humans are interested in.  We hope to leverage this ability to create a code layer that captures enough of the important information about handwritten digits that the digits can be reconstructed.  This technique of taking a network that performs well on one task and repurposing it to another task is called [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning).\n",
    "\n",
    "I want to strip off the layers of ResNET that are more suited to classification, leaving the layers that gather and filter information about images.\n",
    "\n",
    "There is probably a built-in way to do this, but since the structure of fast.ai has changed, I'm not sure where to look, so I get into the guts of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(*list(m.children())[:-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a custom model, I like to have a test vector on which to operate to make sure inputs and outputs are the right shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,_ = next(iter(db.dl()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the data tensor this should make some sense.  The width of the first dimension has changed because our autoencoder will be training on batches of 64 images at once rather than the entire dataset or single images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 2, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(t).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our ResNET encoder is changing the tensor shape.  The first dimension still corresponds with a 64-item batch of data, but the remaining dimensions don't correspond with color channels and image size anymore.  This is to be expected in deep neural networks, each successive layer abstracts the data away from the typology of the input.\n",
    "\n",
    "At this point the output of the encoder is a tensor containing 1024 floats per image in a batch.  From a certain point of view, this makes the autoencoder's task very easy, particularly since the input was only 784 floats!  The point of an autoencoder isn't just to copy the image data to a different format, it's to efficiently encode the essence of the data.  Therefore, we're going to add a layer that cuts down the storage space the encoded image occupies and see how well it can reconstruct the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_sz = 32\n",
    "\n",
    "conv = nn.Conv2d(256, code_sz, kernel_size=(2,2)).cuda()\n",
    "\n",
    "m.add_module('CodeIn',conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(t).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is what our encoded layer looks like.  Now it can only use 32 floats per image for encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct a decoder manually.  Essentially we'll upsample several times until we get to our original size.\n",
    "\n",
    "In more detail, for each upsample we scale the resolution up, then do a trainable 2-d convolution (to allow our network to make changes), and then either a ReLU followed by a batchnorm or a sigmoid.  The idea is to use the sigmoid only on the output layer of the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSample(nn.Module):\n",
    "    def __init__(self,feat_in,feat_out,out_shape=None,scale=2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(feat_in,feat_out,kernel_size=(3,3),stride=1,padding=1)\n",
    "        self.out_shape,self.scale = out_shape,scale\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.conv(\n",
    "            nn.functional.interpolate(\n",
    "                x,size=self.out_shape,scale_factor=self.scale,mode='bilinear',align_corners=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upSamp(feat_in,feat_out, out_shape=None, scale=2, act='relu'):\n",
    "    \n",
    "    upSamp = UpSample(feat_in,feat_out,out_shape=out_shape,scale=scale).cuda()\n",
    "    \n",
    "    layer = nn.Sequential(upSamp)\n",
    "    \n",
    "    if act == 'relu':\n",
    "        act_f = nn.ReLU(inplace=True).cuda()\n",
    "        bn = nn.BatchNorm2d(feat_out).cuda()\n",
    "        layer.add_module('ReLU',act_f)\n",
    "        layer.add_module('BN',bn)\n",
    "    elif act == 'sig':\n",
    "        act_f = nn.Sigmoid()\n",
    "        layer.add_module('Sigmoid',act_f)\n",
    "    return layer\n",
    "\n",
    "def add_layer(m,feat_in,feat_out,name,out_shape=None,scale=2,act='relu'):\n",
    "    upSamp = get_upSamp(feat_in,feat_out,out_shape=out_shape,scale=scale,act=act)\n",
    "    m.add_module(name,upSamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I piece this together carefully, making sure the model layers match up at each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer(m,code_sz,256,'CodeOut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 2, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(t).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer(m,256,128,'Upsample0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(t).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It take a bit of fiddling to end with the exact resolution we want.  It turns out that if we double the resolution in all the layers except this one, and in this one upsample from $4\\times 4$ to $7\\times 7$, then we end up exactly at $28\\times 28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer(m,128,64,'Upsample1',out_shape=(7,7),scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64, 7, 7])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(t).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer(m,64,32,'Upsample2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 14, 14])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(t).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer(m,32,3,'Upsample3',act='sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 28, 28]), torch.Size([64, 3, 28, 28]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(t).size(), t.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our autoencoder is at least outputting objects of the correct shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make learner and choose learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API for creating a learner is slightly different than the old version of fast.ai, with the databunch taking the place of `ModelData`.  Calling the `Learner` constructor (from basic_train.py) seems to be the new preferred way to get a learner, where before very often you were calling a `ConvLearner` class function.  We'll pass the `Learner` our data, model, and a loss function, mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(db,m,loss_func=F.mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lr_find` is much the same as in the past, but the feedback makes it less opaque how to view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find(end_lr=10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`learn.sched.plot()` has become `learn.recorder.plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate finder makes it easier to tune the learning rate hyper-parameter.  The graph shows us how the loss was reacting as `lr_find` dialed up the rate.  We see how far to the right on the graph we can go with the graph still maintaining a nice downward slope.  In my experience this tool is a little less straightforward when applied to autoencoders, so I'm going to be more conservative with the learning rate than the results indicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`learn.fit` is still available as in the older version of fast.ai, but speedy one-cycle training has been wrapped up in `learn.fit_one_cycle`.  I presume the default parameters are good enough, and we'll train 10 epochs at our chosen learning rate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 05:26\n",
      "epoch  train_loss  valid_loss\n",
      "1      0.029886    0.034794    (00:32)\n",
      "2      0.020761    0.021025    (00:32)\n",
      "3      0.016994    0.017409    (00:32)\n",
      "4      0.013616    0.017529    (00:32)\n",
      "5      0.011100    0.011157    (00:32)\n",
      "6      0.009833    0.011554    (00:32)\n",
      "7      0.008426    0.007831    (00:32)\n",
      "8      0.007405    0.006916    (00:33)\n",
      "9      0.006586    0.006059    (00:32)\n",
      "10     0.006256    0.005948    (00:32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10,lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I love the built-in functions that are available now!  The results can be seen by calling `learn.show_results()`.\n",
    "\n",
    "We can see the autoencoder output is slightly different from the input, but overall I'm pretty satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How could we improve this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be able to train the network faster or better if we were using [pixelshuffle](https://arxiv.org/abs/1609.05158) for upscaling.  At a high level, it's apparently a good idea to train the encoder to optimize the code layer rather than the final product (this bears more explanation but I'm not sure I'm equipped to say more, and it's outside the scope of this post).  If we had a more concrete goal for the autoencoder, we could regularize it for sparsity, small gradients, or resilience against noise as described in this [chapter](https://www.deeplearningbook.org/contents/autoencoders.html) of the [free textbook](https://www.deeplearningbook.org/) by Goodfellow, Bengio, and Courville."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for now.  If you'd like to try out this notebook, you can download it <a href=\"https://alanbertl.com/wp-content/uploads/2018/12/MNIST-autoencoder.ipynb\" download>here</a>.  You'll need [Jupyter](https://jupyter.org/).\n",
    "\n",
    "Thanks for reading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
